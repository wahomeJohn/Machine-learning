I'm basically writing this blog for myself because I've been wanting to learn Machine Learning for a while now but have never really got to it. So this blog is more like a journal for me to write about my daily progress - (hopefully I will be making some progress every day).

#100DaysOfMLCode #100ProjectsInML

The best approach for me to learn anything is by working on sample projects. No matter how simple the project is, it helps me better understand the concepts. So I will be working through some small mini projects as part of this learning journey.

There are 100's of excellent resources out there to help you get started. I stumbled upon this A-Z Machine learning course on Udemy and I'll be walking through those examples in the first few weeks.



Today I'll be going through "Simple Linear Regression"

Dataset
First lets look at the dataset. It is Salary_Data.csv and can be found here
It has 2 columns - "Years of Experience" and "Salary" for 30 employees in a company. So in this example, we will train a Simple Linear Regression model to learn the correlation between the number of years of experience of each employee and their respective salary. Once the model is trained, we will be able to do some sample predictions.   

Below is a sample screenshot of the dataset.


So lets get started.

Step 1: Load the Dataset

Below is the code snippet for loading the dataset. 
We will be using the pandas dataframe.
Here X is the independent variable which is the "Years of Experience"
and y is the dependent variable which is the "Salary"

So for X, we specify dataset.iloc[:, :-1].values
which simply means take all rows and all columns except last one

And for y, we specify dataset.iloc[:, 1].values
which simply means take all rows and only columns with index 1 - In python indexes begin at 0 - so index 1 here is the second column which is Salary

# Step 1 Load Data
import pandas as pd
dataset = pd.read_csv('Salary_Data.csv')
X = dataset.iloc[:, :-1].values
y = dataset.iloc[:,1].values

Below is the sample screenshot of X and y

Step 2: Split dataset into training set and test set

Next we have to split the dataset into training and testing. We will use the training dataset for training the model and then check the performance of the model on the test dataset.

For this we will use the train_test_split method from library model_selection
We are providing a test_size of 1/3 which means test set will contain 10 observations and training set will contain 20 observations
The random_state=0 is required only if you want to compare your results with mine.

# Step 2: Split data into training and testing
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=0)

Below is the sample screenshot of X_train, y_train, X_test and y_test

Step 3: Fit Simple Linear Regression model to training set

This is a very simple step. We will be using the LinearRegression class from the library sklearn.linear_model. First we create an object of the LinearRegression class and call the fit method passing the X_train and y_train. 

# Step 3: Fit Simple Linear Regression to Training Data
from sklearn.linear_model import LinearRegression
regressor = LinearRegression()
regressor.fit(X_train, y_train)


Step 4: Predict the test set
Using the regressor we trained in the previous step, we will not use it to predict the results of the test set and compare the predicted values with the actual values

# Step 4: Make Prediction
y_pred = regressor.predict(X_test)

Now we have the y_pred which are the predicted values from our Model and y_test which are the actual values. 
Let us compare are see how well our model did. As you can see from the screenshot below - our basic model did pretty well.

If we take the first employee - the actual salary is 37731 and our model predicted 40835.1 - which is not too bad. There are some predictions that are off but some are pretty close.

Step 5 - Visualizing the training set

Lets visualize the results.
First we'll plot the actual data points of training set - X_train and y_train
plt.scatter(X_train, y_train, color = 'red')

Next we'll plot the regression line - which is the predicted values for the X_train
plt.plot(X_train, regressor.predict(X_train), color='blue')

# Step 5 - Visualize training set results
import matplotlib.pyplot as plt
# plot the actual data points of training set
plt.scatter(X_train, y_train, color = 'red')
# plot the regression line
plt.plot(X_train, regressor.predict(X_train), color='blue')
plt.title('Salary vs Experience (Training set)')
plt.xlabel('Years of Experience')
plt.ylabel('Salary')
plt.show()


Step 6 - Visualizing the test set

Lets visualize the results.
First we'll plot the actual data points of training set - X_test and y_test
plt.scatter(X_test, y_test, color = 'red')

Next we'll plot the regression line - which is the same as above
plt.plot(X_train, regressor.predict(X_train), color='blue')

# Step 6 - Visualize test set results
import matplotlib.pyplot as plt
# plot the actual data points of training set
plt.scatter(X_test, y_test, color = 'red')
# plot the regression line
plt.plot(X_train, regressor.predict(X_train), color='blue')
plt.title('Salary vs Experience (Test set)')
plt.xlabel('Years of Experience')
plt.ylabel('Salary')
plt.show()

Step 7 - Make new predictions
We can also make brand new predictions for data points that do not exist in the dataset.
Like for a person with 15 years experience

new_salary_pred = regressor.predict([[15]])

# Step 7 - Make new prediction
new_salary_pred = regressor.predict([[15]])

Here is the full source code



