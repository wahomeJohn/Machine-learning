#100DaysOfMLCode #100ProjectsInML

Today I'll be looking at the Polynomial Regression example from the A-Z Machine Learning course on Udemy

If you look at the image above which list the equations for all 3 types of Regression - you will notice that in Polynomial Regression we have the same variables x1 but it is raised different powers.

For example 
- instead of x2 - we have x1 raised to the power 2
- instead of x3 - we have x1 raised to the power 3

Lets explore the dataset.

Dataset
First lets look at the dataset. It is Position_Salaries.csv and can be found here
It has 3 columns - "Position", "Level" and "Salary" and describes the approximate salary range for an employee based on what level he falls under.

For example if an employee is a Manager - he falls in Level 4 and should get around $80,000.

Below is the screenshot of the dataset.

Project Objective
Lets assume the above table is what the HR team of a company uses to determine what salary to offer to a new employee. For our project, let's take an example that an employee has applied for the role of a Regional Manager and has already worked as a Regional Manager for 2 years. So based on the table above - he falls between level 6 and level 7 - Lets say he falls under level 6.5

We want to build a model to predict what salary we should offer this new employee.

Let's get started.

Step 1: Load the Dataset

If we look at the dataset, we need to predict the salary for an employee who falls under Level 6.5 - So we really do not need the first column "Position".

Here X is the independent variable which is the "Level"
and y is the dependent variable which is the "Salary"

So for X, we specify 

X = dataset.iloc[:, 1:2].values

which simply means take all rows and all columns from index 1 upto index 2 but not including index 2 (upper bound range is not included)

And for y, we specify dataset.iloc[:, 2].values
which simply means take all rows and only columns with index 2 - In python indexes begin at 0 - so index 2 here is the second column which is Salary

# Step 1 - Load Data
import pandas as pd
dataset = pd.read_csv("Position_Salaries.csv")
X = dataset.iloc[:, 1:2].values
y = dataset.iloc[:, 2].values

*********************************

Step 2: Fit Linear Regression model to dataset

First we will build a simple linear regression model to see what prediction it makes and then compare it to the prediction made by the Polynomial Regression to see which is more accurate.

We will be using the LinearRegression class from the library sklearn.linear_model. We create an object of the LinearRegression class and call the fit method passing the X and y. 

# Step 2 - Fitting Linear Regression
from sklearn.linear_model import LinearRegression
lin_reg = LinearRegression()
lin_reg.fit(X,y)

********************************

Step 3: Visualize Linear Regression Results

Lets plot the graph to look at the results for Linear Regression

# Step 3 - Visualize Linear Regression Results
import matplotlib.pyplot as plt

plt.scatter(X,y, color="red")
plt.plot(X, lin_reg.predict(X))
plt.title("Linear Regression")
plt.xlabel("Level")
plt.ylabel("Salary")
plt.show()

If we look at the graph, we can see that a person at level 6.5 should be offered a salary of around $300k. We will confirm this in next step.

***********************************

Step 4: Predict Linear Regression Results

# Step 4 prediction
lin_reg.predict([[6.5]])

We can see that the prediction is way off as it predicts $330k.

Now lets check the predictions by implementing Polynomial Regression

***********************************

Step 5: Convert X to polynomial format

For Polynomial Regression, we need to transform our matrix X to X_poly where X_poly will contain X to the power of n - depending upon the degree we choose. If we choose degree 2, then X_poly will contain X and X to the power 2. If we choose degree 3, then X_poly will contain X, X to the power 2 and X to the power 3.

We will be using the PolynomialFeatures class from the sklearn.preprocessing library for this purpose. When we create an object of this class - we have to pass the degree parameter. Lets begin by choose degree as 2. Then we call the fit_transform method to transform matrix X.

# Step 5 - Convert X to polynomial format
from sklearn.preprocessing import PolynomialFeatures
poly_reg = PolynomialFeatures(degree=2)
X_poly = poly_reg.fit_transform(X)

Lets look at X_poly

If you see, the 2nd column is the actual levels from 1 to 10 present in X.
The 3rd column contains X raised to the power 2 (as we chose degree 2)
The first column contains just 1's - This is automatically added by the PolynomialFeatures class to include the constant b0.

*********************************

Step 6: Fitting Polynomial Regression

Now we will create a new linear regression object called lin_reg_2 and pass X_poly to it instead of X that we passed in Step 2.

 # Step 6 - Passing X_poly to LinearRegression
lin_reg_2 = LinearRegression()
lin_reg_2.fit(X_poly,y)

*********************************

Step 7: Visualize Poly Regression Results

Lets plot the graph to look at the results for Polynomial Regression

# Step 7 - Visualize Poly Regression Results
plt.scatter(X,y, color="red")
plt.plot(X, lin_reg_2.predict(poly_reg.fit_transform(X)))
plt.title("Poly Regression Degree 2")
plt.xlabel("Level")
plt.ylabel("Salary")
plt.show()

If we look at the graph, we can see that a person at level 6.5 should be offered a salary of around $190k. We will confirm this in next step.

********************************

Step 8: Predict Polynomial Regression Results

We get a prediction of $189k

# Step 8 prediction
lin_reg_2.predict(poly_reg.fit_transform([[6.5]]))

********************************

Step 9 - Change degree to 3 and run steps 5-8

# Step 5 - Convert X to polynomial format
from sklearn.preprocessing import PolynomialFeatures
poly_reg = PolynomialFeatures(degree=3)
X_poly = poly_reg.fit_transform(X)

 # Step 6 - Passing X_poly to LinearRegression
lin_reg_2 = LinearRegression()
lin_reg_2.fit(X_poly,y)

# Step 7 - Visualize Poly Regression Results
plt.scatter(X,y, color="red")
plt.plot(X, lin_reg_2.predict(poly_reg.fit_transform(X)))
plt.title("Poly Regression Degree 3")
plt.xlabel("Level")
plt.ylabel("Salary")
plt.show()

# Step 8 prediction
lin_reg_2.predict(poly_reg.fit_transform([[6.5]]))

We get a prediction of $133k

*********************************

Step 10 - Change degree to 4 and run steps 5-8

# Step 5 - Convert X to polynomial format
from sklearn.preprocessing import PolynomialFeatures
poly_reg = PolynomialFeatures(degree=4)
X_poly = poly_reg.fit_transform(X)

 # Step 6 - Passing X_poly to LinearRegression
lin_reg_2 = LinearRegression()
lin_reg_2.fit(X_poly,y)

# Step 7 - Visualize Poly Regression Results
plt.scatter(X,y, color="red")
plt.plot(X, lin_reg_2.predict(poly_reg.fit_transform(X)))
plt.title("Poly Regression Degree 4")
plt.xlabel("Level")
plt.ylabel("Salary")
plt.show()

# Step 8 prediction
lin_reg_2.predict(poly_reg.fit_transform([[6.5]]))

We get a prediction of $158k which looks reasonable based on our dataset.

So in this case by using Linear Regression - we got a prediction of $330k and by using Polynomial Regression we got a prediction of 158k.

Here is the full source code.